{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d39109-76e8-4031-a8f4-2ac271b74f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your number of available CPU workers is: 4\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "#-----------------------------\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Sci-kit learn packages\n",
    "#-----------------------------\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Modelling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Metrics\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "\n",
    "# Other packages\n",
    "#-----------------------------\n",
    "from time import time #Time algorithms\n",
    "import pickle # Save or upload models\n",
    "import multiprocessing\n",
    "print(f'Your number of available CPU workers is: {multiprocessing.cpu_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf4240-6413-44ec-82a3-0073295001e3",
   "metadata": {},
   "source": [
    "As in the [previous notebook](./2%20-%20Logistic%20Regression%201%20-%20Model%20selection.ipynb) , we ignore all warnings for better readability (only after the code has been tested)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e7f68c-b3e7-42ff-957a-5d55c44858bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d99f38-f92b-43bc-a4bf-1c891be45da6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa50fd3-174d-498e-a028-c63932ba0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics = pd.read_csv('./Dataset/clean_lyrics.csv', keep_default_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f2b8ea-faa9-40b8-9771-7f3da92db603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>multiple_letter</th>\n",
       "      <th>Trails</th>\n",
       "      <th>lyrics_clean</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Hip_hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World So Cold</td>\n",
       "      <td>It starts with pain, followed by hate. Fueled ...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>start pain follow hate fuel endless question o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Broken</td>\n",
       "      <td>Freedom!. Alone again again alone. Patiently w...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>freedom alon alon patient wait phone hope call...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 Leaf Loser</td>\n",
       "      <td>Biting the hand that feeds you, lying to the v...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>bite hand feed lie voic insid reach beg someth...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthem For The Underdog</td>\n",
       "      <td>You say you know just who I am. But you can't ...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>say know imagin wait across line thought still...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adrenaline</td>\n",
       "      <td>My heart is beating faster can't control these...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0</td>\n",
       "      <td>heart beat faster control feel anymor wait lon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SName                                              Lyric  \\\n",
       "0            World So Cold  It starts with pain, followed by hate. Fueled ...   \n",
       "1                   Broken  Freedom!. Alone again again alone. Patiently w...   \n",
       "2             3 Leaf Loser  Biting the hand that feeds you, lying to the v...   \n",
       "3  Anthem For The Underdog  You say you know just who I am. But you can't ...   \n",
       "4               Adrenaline  My heart is beating faster can't control these...   \n",
       "\n",
       "      Artist  Genre  multiple_letter  Trails  \\\n",
       "0  12 Stones      0         0.000000       0   \n",
       "1  12 Stones      0         0.000000       0   \n",
       "2  12 Stones      0         0.000000       0   \n",
       "3  12 Stones      0         0.000000       2   \n",
       "4  12 Stones      0         0.007042       0   \n",
       "\n",
       "                                        lyrics_clean  Rock  Pop  Hip_hop  \n",
       "0  start pain follow hate fuel endless question o...     1    0        1  \n",
       "1  freedom alon alon patient wait phone hope call...     1    1        0  \n",
       "2  bite hand feed lie voic insid reach beg someth...     1    1        0  \n",
       "3  say know imagin wait across line thought still...     1    0        0  \n",
       "4  heart beat faster control feel anymor wait lon...     0    0        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78782543-ba5b-4966-8e36-49bd08f1d0c7",
   "metadata": {},
   "source": [
    "# Prepping the data for modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f6908-0de8-4c20-a042-2a4453323c64",
   "metadata": {},
   "source": [
    "## Word Vectorizer Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96270383-7425-4a5e-95b4-2b85c5129c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                             tokenizer = None,\n",
    "                             preprocessor = None,\n",
    "                             stop_words = None,\n",
    "                             max_features = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e81428-4363-4b58-92b9-69c33e7dc95c",
   "metadata": {},
   "source": [
    "## Function Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a30193-03d2-4f62-a503-f4987f5d476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apr(y_pred, y_real):\n",
    "    \n",
    "    '''This function takes in the real and predicted values of the target.\n",
    "    It returns the following performance metrics: accuracy, precision, recall and F1-score'''\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_real, y_pred) ## From sklearn, get the accuracy\n",
    "    precision = metrics.precision_score(y_real, y_pred, average='weighted') ## precision\n",
    "    recall = metrics.recall_score(y_real, y_pred, average='weighted') ## recall\n",
    "    f1 = metrics.f1_score(y_real, y_pred, average='weighted') ## F1\n",
    "    \n",
    "    ''' Print them into a readable format '''\n",
    "    print(f\"Accuracy:{accuracy}\")\n",
    "    print(f\"Precision:{precision}\")\n",
    "    print(f\"Recall:{recall}\")\n",
    "    print(f'F1:{f1}')\n",
    "    \n",
    "    return accuracy, precision, recall, f1 ## return them in case we need to save them in non-local variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582980da-33de-486d-8aa0-6ca8387ecec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enriched_prep(features):\n",
    "        \n",
    "    assert(type(features)==list), \"Please input your desired features for enrichment in a LIST format (even if only one\\\n",
    "    feature is being invoked!)\"\n",
    "    \n",
    "    X = df_lyrics[features + ['lyrics_clean']]\n",
    "    y = df_lyrics[['Genre']]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.copy(), y.copy(), test_size = 0.2, random_state = 42, stratify=y)\n",
    "    \n",
    "    \n",
    "    if 'Trails' in features:\n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        X_train['Trails'] = scaler.fit_transform(X_train['Trails'].values.reshape(-1, 1))\n",
    "        X_test['Trails'] = scaler.transform(X_test['Trails'].values.reshape(-1, 1))\n",
    "        \n",
    "    lyrics_to_vec_train = vectorizer.fit_transform(X_train.lyrics_clean)\n",
    "    lyrics_to_vec_test = vectorizer.transform(X_test.lyrics_clean)\n",
    "    \n",
    "    lyrics_to_vec_train = pd.DataFrame(lyrics_to_vec_train.toarray(), index = X_train.index)\n",
    "    lyrics_to_vec_test = pd.DataFrame(lyrics_to_vec_test.toarray(),  index = X_test.index)\n",
    "    \n",
    "    X_train = pd.concat([lyrics_to_vec_train, X_train[features]], axis=1)\n",
    "    X_test = pd.concat([lyrics_to_vec_test, X_test[features]], axis=1)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e14ece3-e9fb-4638-8f9b-915a63be44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enriched_logit_reg(features):\n",
    "\n",
    "    now = time()\n",
    "    logreg = LogisticRegression(max_iter=200, solver='newton-cg',penalty='l2',\n",
    "                               n_jobs = multiprocessing.cpu_count()-1, C=1)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    print(\"Time elapsed in seconds: {}\".format(time()-now), \"\\n\")\n",
    "    \n",
    "    #print(apr(logreg.predict(X_test), y_test))\n",
    "    \n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144cd7e-e5e5-45ba-9efb-5ebdc10296c6",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac594fcc-1545-461a-97c5-d4831225f801",
   "metadata": {},
   "source": [
    "### Testing and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a456d3e2-8b32-4a6e-8356-1b2140b6d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Trails', 'Rock', 'Pop', 'Hip_hop']\n",
    "X_train, X_test, y_train, y_test = Enriched_prep(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b99023-f3f4-4562-bf30-463835e4208f",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "We perform a Logistic Regression based on the best parameters found in the [Model selection](./2%20-%20Logistic%20Regression%201%20-%20Model%20selection.ipynb) notebook, that is:\n",
    " - Data prepped using the Snowball Stemmer\n",
    " - Newton solver\n",
    " - L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225c983-4ff3-4d52-9532-bf1e2f916bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Enriched_logit_reg(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befebb0d-cf15-4302-ba25-519174def843",
   "metadata": {},
   "source": [
    "We save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f43959-a814-4c10-ae2d-baad6a8a54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='logit_model.sav'\n",
    "\n",
    "# Save the model\n",
    "#pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# Load the model\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400ad39-12d0-42cd-8697-c2c1045898e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c19bbdbf-2a9b-4ae6-9ba5-6ea59cd67971",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['pred'] = model.predict(X_train) # Prediction for the training set\n",
    "y_test['pred'] = model.predict(X_test) # Prediction for the testing set\n",
    "\n",
    "all_pred = pd.concat([y_test['pred'], y_train['pred']], names = 'pred_logit') # Concatenate the predictions together\n",
    "\n",
    "# Add all predictions to the main dataframe\n",
    "df_lyrics = pd.merge(df_lyrics, all_pred, how='inner', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7541e1-e3fa-446e-946b-c5190e537c4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ec913b-cd70-4ad4-ab6a-f1f3a442d241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d85f8776-8efc-467b-8ec7-8b56b1a2b215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train['pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed4984-8668-4d51-ae6d-dad730638c08",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "237e0081-8cd8-4621-8075-ca6806e3bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    12558\n",
       "0     3684\n",
       "1     2945\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.loc[df_lyrics.pred != df_lyrics.Genre, 'Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80626ab8-4817-433a-99d6-a29e0934f9ed",
   "metadata": {},
   "source": [
    "Most misclassified songs are Pop songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5706d28b-7516-4e59-b8da-5a99755a057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24% of the songs were misclassified.\n",
      "Among the missclassified songs, 65% were pop songs.\n"
     ]
    }
   ],
   "source": [
    "missclassified = df_lyrics.loc[df_lyrics.pred != df_lyrics.Genre, 'Genre'].count()\n",
    "missclassified_pop = df_lyrics.loc[df_lyrics.pred != df_lyrics.Genre, 'Genre'].value_counts()[2]\n",
    "print(f'{missclassified/df_lyrics.shape[0]:.0%} of the songs were misclassified.')\n",
    "\n",
    "print(f'Among the missclassified songs, {missclassified_pop/missclassified:.0%} were pop songs.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
