{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34f55a23-832f-4001-ba39-9c16c0fd05d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rigau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rigau\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "#-----------------------------\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Natural Laguage Processing\n",
    "#-----------------------------\n",
    "import nltk\n",
    "\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Punctuation\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "# Stemmers and Lemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "\n",
    "# Other packages\n",
    "#-----------------------------\n",
    "\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25441f9-f177-48cb-88c5-e8c97e7cf0ac",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e81f6f3-6125-493e-84ae-5199ba1a697d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data set/artists-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1972/1351308416.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0martist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Data set/artists-data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlyrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Dataset/lyrics-data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Data set/artists-data.csv'"
     ]
    }
   ],
   "source": [
    "artist = pd.read_csv('./Data set/artists-data.csv')\n",
    "lyrics = pd.read_csv('./Dataset/lyrics-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2ecb0-9d6e-455f-a809-1ac57abb4a26",
   "metadata": {},
   "source": [
    "## Artist dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8679c5-533b-4fdf-a4f4-dbcdea1d52d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Songs</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Link</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 Maniacs</td>\n",
       "      <td>110</td>\n",
       "      <td>0.3</td>\n",
       "      <td>/10000-maniacs/</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Rock; Pop; Electronica; Dance; J-Pop/J-Rock; G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Stones</td>\n",
       "      <td>75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>/12-stones/</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Rock; Gospel/Religioso; Hard Rock; Grunge; Roc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>311</td>\n",
       "      <td>196</td>\n",
       "      <td>0.5</td>\n",
       "      <td>/311/</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Rock; Surf Music; Reggae; Ska; Pop/Rock; Rock ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 Non Blondes</td>\n",
       "      <td>15</td>\n",
       "      <td>7.5</td>\n",
       "      <td>/4-non-blondes/</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Rock; Pop/Rock; Rock Alternativo; Grunge; Blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Cruz Está Vazia</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/a-cruz-esta-vazia/</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Artist  Songs  Popularity                 Link Genre  \\\n",
       "0      10000 Maniacs    110         0.3      /10000-maniacs/  Rock   \n",
       "1          12 Stones     75         0.3          /12-stones/  Rock   \n",
       "2                311    196         0.5                /311/  Rock   \n",
       "3      4 Non Blondes     15         7.5      /4-non-blondes/  Rock   \n",
       "4  A Cruz Está Vazia     13         0.0  /a-cruz-esta-vazia/  Rock   \n",
       "\n",
       "                                              Genres  \n",
       "0  Rock; Pop; Electronica; Dance; J-Pop/J-Rock; G...  \n",
       "1  Rock; Gospel/Religioso; Hard Rock; Grunge; Roc...  \n",
       "2  Rock; Surf Music; Reggae; Ska; Pop/Rock; Rock ...  \n",
       "3  Rock; Pop/Rock; Rock Alternativo; Grunge; Blue...  \n",
       "4                                               Rock  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da7ffe7-e8a4-4059-8a8e-1050a36dec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The artist dataframe has 3242 rows and 6 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'The artist dataframe has {artist.shape[0]} rows and {artist.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c261e6a3-eb96-4d0d-b519-2df392cb10bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock            797\n",
       "Pop             796\n",
       "Sertanejo       617\n",
       "Hip Hop         537\n",
       "Funk Carioca    302\n",
       "Samba           193\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105e17e-67d2-44a2-b45a-d6e113167e16",
   "metadata": {},
   "source": [
    "We only keep the Rock, Hip Hop and Pop songs, as most of them have lyrics in English.\n",
    "The other genres are most likely made of songs in Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f1f2fc-e9bb-4bef-8389-50365895aa49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2130, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = artist[artist.Genre.isin(['Rock','Hip Hop','Pop'])]\n",
    "\n",
    "artist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd8f29-9ae3-4383-a3e9-8117e6003e1a",
   "metadata": {},
   "source": [
    "We still have 65% of the original dataframe.\n",
    "\n",
    "We now check if there are any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48385a05-a108-41ea-bb63-b4156c987fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist        0\n",
       "Songs         0\n",
       "Popularity    0\n",
       "Link          0\n",
       "Genre         0\n",
       "Genres        4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026d168-afdd-4cf4-9a0f-cd01089bea5c",
   "metadata": {},
   "source": [
    "The null values in Genres are not an issue, as they indicate if artists belong to multiple genre, outside of their main one.\n",
    "We will not use this data for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325ecc1c-2a15-412b-8955-4bd78544a324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "1        1841\n",
       "2         143\n",
       "3           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_per_artist = artist.groupby(['Artist'])[['Genre']].count()\n",
    "genre_per_artist.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc86e1-4a8a-41c4-8159-12b526a30b63",
   "metadata": {},
   "source": [
    "Some artists belong two 2 or more different (main) music genre. We will not keep them, to avoid any ambiguity when trying to classify the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b50d9d05-149b-4c5e-98aa-46a4a45a3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_1_genre = genre_per_artist[genre_per_artist.Genre == 1].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1db102-aa7f-4db4-a1cc-50127561e166",
   "metadata": {},
   "source": [
    "## Lyrics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43a872d5-1578-4dd0-a29a-beaca3894906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Idiom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/10000-maniacs/</td>\n",
       "      <td>More Than This</td>\n",
       "      <td>/10000-maniacs/more-than-this.html</td>\n",
       "      <td>I could feel at the time. There was no way of ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/10000-maniacs/</td>\n",
       "      <td>Because The Night</td>\n",
       "      <td>/10000-maniacs/because-the-night.html</td>\n",
       "      <td>Take me now, baby, here as I am. Hold me close...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/10000-maniacs/</td>\n",
       "      <td>These Are Days</td>\n",
       "      <td>/10000-maniacs/these-are-days.html</td>\n",
       "      <td>These are. These are days you'll remember. Nev...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/10000-maniacs/</td>\n",
       "      <td>A Campfire Song</td>\n",
       "      <td>/10000-maniacs/a-campfire-song.html</td>\n",
       "      <td>A lie to say, \"O my mountain has coal veins an...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/10000-maniacs/</td>\n",
       "      <td>Everyday Is Like Sunday</td>\n",
       "      <td>/10000-maniacs/everyday-is-like-sunday.html</td>\n",
       "      <td>Trudging slowly over wet sand. Back to the ben...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ALink                    SName  \\\n",
       "0  /10000-maniacs/           More Than This   \n",
       "1  /10000-maniacs/        Because The Night   \n",
       "2  /10000-maniacs/           These Are Days   \n",
       "3  /10000-maniacs/          A Campfire Song   \n",
       "4  /10000-maniacs/  Everyday Is Like Sunday   \n",
       "\n",
       "                                         SLink  \\\n",
       "0           /10000-maniacs/more-than-this.html   \n",
       "1        /10000-maniacs/because-the-night.html   \n",
       "2           /10000-maniacs/these-are-days.html   \n",
       "3          /10000-maniacs/a-campfire-song.html   \n",
       "4  /10000-maniacs/everyday-is-like-sunday.html   \n",
       "\n",
       "                                               Lyric    Idiom  \n",
       "0  I could feel at the time. There was no way of ...  ENGLISH  \n",
       "1  Take me now, baby, here as I am. Hold me close...  ENGLISH  \n",
       "2  These are. These are days you'll remember. Nev...  ENGLISH  \n",
       "3  A lie to say, \"O my mountain has coal veins an...  ENGLISH  \n",
       "4  Trudging slowly over wet sand. Back to the ben...  ENGLISH  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "520af0c4-3253-4010-8de1-0b3f15d2d7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lyrics dataframe has 209522 rows and 5 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'The lyrics dataframe has {lyrics.shape[0]} rows and {lyrics.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980325e7-458d-43cb-b017-ab92eeb306f1",
   "metadata": {},
   "source": [
    "We keep the songs in English only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba248657-5667-42d4-92da-8e78489c1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = lyrics[lyrics.Idiom == 'ENGLISH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ba69a-cee0-48ed-99b3-6c271cf18e2a",
   "metadata": {},
   "source": [
    "While we lose about 50% of the dataset by doing this, we still have 114,723 songs in the dataset, which will be sufficiant for modelling.\n",
    "\n",
    "We now check if there are any null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7cdcb74-3195-437f-8d81-d036ca5aaf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALink    0\n",
       "SName    0\n",
       "SLink    0\n",
       "Lyric    0\n",
       "Idiom    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5423f037-9b90-49cd-81bc-a15e91bbed00",
   "metadata": {},
   "source": [
    "## Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b95b608-1838-4f46-8699-4541b7c6f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics = artist.merge(lyrics, left_on='Link', right_on='ALink', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b46c9d3-39f8-4c30-b6a7-22db295bf564",
   "metadata": {},
   "source": [
    "We now drop the duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9db3d9f-c01c-4eaf-a639-450004ce67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics = df_lyrics.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62bd9ba-0c8c-43ed-b2f1-109f0fc692b5",
   "metadata": {},
   "source": [
    "We keep the songs where the artists only belong to 1 principal music genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e876ce98-a124-49c2-896d-36ba3d10a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics = df_lyrics[df_lyrics.Artist.isin(artist_1_genre)]\n",
    "df_lyrics = df_lyrics.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8393beb5-519d-43e3-acc3-f3be51cf8b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1023 different artists.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(df_lyrics.Artist.unique())} different artists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d96a1dea-26be-42c8-89ee-299c78bdf090",
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre_dict = {'Rock':0, 'Hip Hop':1, 'Pop':2}\n",
    "df_lyrics['Genre'] = df_lyrics['Genre'].map(Genre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afbd9743-6570-4b82-9137-8bd15c9e8058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Songs</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Link</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Genres</th>\n",
       "      <th>ALink</th>\n",
       "      <th>SName</th>\n",
       "      <th>SLink</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Idiom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 Stones</td>\n",
       "      <td>75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>/12-stones/</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock; Gospel/Religioso; Hard Rock; Grunge; Roc...</td>\n",
       "      <td>/12-stones/</td>\n",
       "      <td>World So Cold</td>\n",
       "      <td>/12-stones/world-so-cold.html</td>\n",
       "      <td>It starts with pain, followed by hate. Fueled ...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Stones</td>\n",
       "      <td>75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>/12-stones/</td>\n",
       "      <td>0</td>\n",
       "      <td>Rock; Gospel/Religioso; Hard Rock; Grunge; Roc...</td>\n",
       "      <td>/12-stones/</td>\n",
       "      <td>Broken</td>\n",
       "      <td>/12-stones/broken.html</td>\n",
       "      <td>Freedom!. Alone again again alone. Patiently w...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Artist  Songs  Popularity         Link  Genre  \\\n",
       "0  12 Stones     75         0.3  /12-stones/      0   \n",
       "1  12 Stones     75         0.3  /12-stones/      0   \n",
       "\n",
       "                                              Genres        ALink  \\\n",
       "0  Rock; Gospel/Religioso; Hard Rock; Grunge; Roc...  /12-stones/   \n",
       "1  Rock; Gospel/Religioso; Hard Rock; Grunge; Roc...  /12-stones/   \n",
       "\n",
       "           SName                          SLink  \\\n",
       "0  World So Cold  /12-stones/world-so-cold.html   \n",
       "1         Broken         /12-stones/broken.html   \n",
       "\n",
       "                                               Lyric    Idiom  \n",
       "0  It starts with pain, followed by hate. Fueled ...  ENGLISH  \n",
       "1  Freedom!. Alone again again alone. Patiently w...  ENGLISH  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d1ded-c025-4c43-a24a-1c221134104e",
   "metadata": {},
   "source": [
    "For convenience and readability we will only keep a few columns, as we will not be using the others ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09235ce9-ba61-4d65-9727-6ec2eb4b1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics = df_lyrics[['SName', 'Lyric','Artist', 'Genre']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62a011b0-78b7-4b1f-bb2c-76836c2e7d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have a dataframe made of 79452 different songs, ready for cleaning.\n"
     ]
    }
   ],
   "source": [
    "print(f'We now have a dataframe made of {df_lyrics.shape[0]} different songs, ready for cleaning.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b8a3b-fbc1-4ac0-b9fe-f69505bfdf65",
   "metadata": {},
   "source": [
    "We now export the dataframe, to save a copy of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6216e3ec-0be7-4535-be01-2e45b26347b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.to_csv('./Dataset/music_1_genre.csv', index = False)\n",
    "\n",
    "#df_lyrics = pd.read_csv('./Dataset/music_1_genre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a45afe-1250-49d9-b2f1-4008ac31e8b8",
   "metadata": {},
   "source": [
    "## Radom lyrics sample\n",
    "\n",
    "We have a look at a few songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fe2771f-2e24-413e-9d8f-f0cc790e1627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(feat. Mannie Fresh). [Intro: Baby]. Uh huh uh huh. Cut me up in my head, Cut me up nigga fuck. Ay ay Fresh, its all gravy baby. Its my turn nigga, I'm under the burn biotch. If you ain't getting money, you's a crazy motherfucker (got to be a crazy motherfucker). I ain't getting money, I'm probably a crazy motherfucker (lord help me). This is a biotch, biotch. [Baby]. Come on nigga. Its them pimpin, ballin, gangster macks. Theys old school caddies with them bows and racks. The new school bens with them bows to match. But its the Birdman daddy got them O's of crack. A nigga off the diet cause a nigga gettin fat. Them throwback jerseys with them throwback hats. Burberry timbs with the fence to match. And I'm so so fly, and mommy like that. Ounces of that purple and we do it by the sac. Rag-top bens with them rag-top lacs. Nothing to a gangsta nigga choak your strap. We live for money, hoes cooking that crap. Them 20\" rims and them tires are flat. There ain't no question, that stunna is a mack. A nigga thought it was over but bitch we back. With daimonds in the middle PIMP, daimonds in the back BITCH. [Chorus: Mannie Fresh - repeat 2X]. Every Place that I went to. About a hundrend bad broads say they sent you. A picture of themselves but naked, ya heard. They all wanna be Ms. Bird, Ms. Bird. [Baby]. You know I got that Crystal on the rocks. You see a nigga's jewels, no name on the watch. Until a nigga die these cops gon watch. But I don't give a fuck nigga, the shit don't stop. All I'm trying to do is stack a knot. Them aligator seats with them brand new drops. Them hoes gonna jock cause they see a nigga hot. Riding on my jet skiis behind a nigga yot. Ten up in my ear ma ten up on a watch. Real hot girls gonna jock a spot. So grab a nigga dick bitch drop it like its hot. The same old nigga off them up-town blocks. I came around your corner and I shit your spot. It's (?) and I serve your block. A Cash Money hot boy and I pop the lock. A know beat boy with the rooka rooka rock biotch. [Chorus - 2X]. [Mannie Fresh]. Now Dada, Barbara, Kiesha, Tarisa and Dawn. I'm tired of having sex and I want to go home. But I cant leave yet cause they kissing each other. Plus I'm hot and I'm horny, I'm getting my rubbers. What that tatoo on your tittie say, Hood Rich. Let me your ass, oh wolves' bitch. God damn Ms. Kiesha ain't your momma a teacher. Your sister is a mister and your daddys a preacher. Now you's a mixed up screwed down dike type chick. If you ain't eating pussy then you sucking good dick. Now every place that I go to. About a hundred grimey niggas say the know you. And they all got that movie that you made with that man. Don Da Don Don Don, stop playin. If you seeee, the movieeee (triple x bitoch). [Chorus - 2X] \n",
      "\n",
      "Genre: Hip Hop\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "There's such a sad love. Deep in your eyes.. A kind of pale jewel. Open and closed. Within your eyes.. I'll place the sky. Within your eyes.. There's such a fooled heart. Beatin' so fast. In search of new dreams.. A love that will last. Within your heart.. I'll place the moon. Within your heart.. As the pain sweeps through,. Makes no sense for you.. Every thrill is gone.. Wasn't too much fun at all,. But I'll be there for you-ou-ou. As the world falls down.. Falling.. As the world falls down.. Falling.. Falling in love.. I'll paint you mornings of gold.. I'll spin you Valentine evenings.. Though we're strangers 'til now,. We're choosing the path. Between the stars.. I'll leave my love. Between the stars.. As the pain sweeps through,. Makes no sense for you.. Every thrill is gone.. Wasn't too much fun at all,. But I'll be there for you-ou-ou. As the world falls down.. Falling. As the world falls down.. Falling. Falling. As the world falls down.. Falling.. Falling.. Falling. Falling in love. As the world falls down.. Falling.. Falling.. Falling.. Falling in love. As the world falls down.. Makes no sense at all.. Makes no sense to fall.. Falling. As the world falls down.. Falling.. Falling.. Falling in love. As the world falls down.. Falling.. Falling. Falling in love. Falling in love. Falling in love. Falling in love. Falling in love \n",
      "\n",
      "Genre: Rock\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "It called me, I shoulda known. As the fever sweat through the dream. Told mamma that I couldn't go. So I could stay home just to watch him dancing. And you could not tell me then. Like you could never ever tell me now. That this is not who I am. Plans were made while my back was turned. Said Baby, That is no way to live. Showed me that carrot on a string but just a little too late. The bite from the taste and the smell of the sick somehow reminds me to be myself. Over and over again. Wanna be startin' somethin' taught me to sing. Or maybe kiss kiss Molly's lips. On a plain he will always live. In a round he will always be dancing. Imagine where I'd be now. On these four legs I stand proud. It's the only way I know how to give \n",
      "\n",
      "Genre: Rock\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(10)\n",
    "dict = {0:'Rock', 1:'Hip Hop', 2:'Pop'}\n",
    "\n",
    "for item in sample(range(len(df_lyrics)), 3):\n",
    "    print(df_lyrics['Lyric'][item], \"\\n\")\n",
    "    print(\"Genre: {}\".format(dict.get(df_lyrics['Genre'][item])))\n",
    "    print(\"\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355f6687-b3b8-45bc-9d6f-3362bebad8b3",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97b02c-1d8a-4b99-911f-4d6b88ddc5de",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eace4b4f-9896-43d7-819c-b0833a1ff656",
   "metadata": {},
   "source": [
    "Before cleaning the data, we explore what kind of stemmers are available, that is:\n",
    " - Porter Stemmer\n",
    " - Lancaster Stemmer\n",
    " - Snowball Stemmer\n",
    " \n",
    "Because of the computational requirement for lemmatizing, we will only stem the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecf7cdce-d138-4070-8143-26c75c70f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "l_stemmer = LancasterStemmer()\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f534b3a7-21fb-498a-a82a-28fba1bdcbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_str = ['apparatus', 'applicable', 'apply', 'apple', 'appletown', \n",
    "          'AppleTown', 'apples', 'apply', 'app', 'application', 'applied', 'applies', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6595f998-d5fa-42e4-af25-ecbfc3898914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StemTest(my_str=my_str):\n",
    "    ''' Testing various words on a selection of stemmers and lemmatizers '''\n",
    "    \n",
    "    assert(type(my_str)==list), \"Please input your selection of words as a LIST!\"\n",
    "    my_str_1 = [p_stemmer.stem(x) for x in my_str] ## Use the Porter stemmer\n",
    "    my_str_2 = [l_stemmer.stem(x) for x in my_str] ## Use the Lancaster stemmer\n",
    "    my_str_3 = [s_stemmer.stem(x) for x in my_str] ## Use the Snowball stemmer\n",
    "    my_str_4 = [lemma.lemmatize(x) for x in my_str]\n",
    "    quick_dict = {1:'Porter: ', 2:'Lancaster: ', 3:\"Snowball: \", 4:'Lemmatizer:'}\n",
    "\n",
    "    ## Output our results from all stemmers, together with the original string\n",
    "    print(\"Original: \", my_str, \"\\n\")\n",
    "    for i in range(1,5):\n",
    "        print(quick_dict[i], locals()['my_str_{}'.format(i)], sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e04dc0-bbc8-41b9-a595-49dac781e03e",
   "metadata": {},
   "source": [
    "We play aroung with the different stemmers/lemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "932c3202-f048-4c58-82b5-26c083f21ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "StemTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b190288-c3e4-4ef8-ad18-31bd5daf0c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['try', 'tryy', 'tryyy', 'tryyyy', \"tryin'\"] \n",
      "\n",
      "Porter:  ['tri', 'tryy', 'tryyi', 'tryyyy', \"tryin'\"]\n",
      "Lancaster:  ['try', 'tryy', 'tryyy', 'tryyyy', \"tryin'\"]\n",
      "Snowball:  ['tri', 'tryy', 'tryyi', 'tryyyy', 'tryin']\n",
      "Lemmatizer: ['try', 'tryy', 'tryyy', 'tryyyy', \"tryin'\"]\n"
     ]
    }
   ],
   "source": [
    "StemTest(['try', 'tryy', 'tryyy', 'tryyyy', 'tryin\\''])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c2583-9006-4bd7-9f47-3dbb75a8b60a",
   "metadata": {},
   "source": [
    "None of the stemmers or lemmatizer seem to be dealing well with words ending by multiple instances of the same letter (commonly found in song lyrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d31dc4e5-042b-4827-907f-c7c896f0f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['yeeeaaaahhhhh'] \n",
      "\n",
      "Porter:  ['yeeeaaaahhhhh']\n",
      "Lancaster:  ['yeeeaaaahhhhh']\n",
      "Snowball:  ['yeeeaaaahhhhh']\n",
      "Lemmatizer: ['yeeeaaaahhhhh']\n"
     ]
    }
   ],
   "source": [
    "StemTest(['yeeeaaaahhhhh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf32e9e-8bfc-4455-beb3-1404d253d3e8",
   "metadata": {},
   "source": [
    "Similar observation when the repetition of the letter is within a word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12470d1-895d-4084-97b0-194fc63f1a7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data cleaning using Regex\n",
    "\n",
    "To solve the letter repetition within words issue, we will use regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f6afc73-633a-47cd-8671-d252a816805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_clean(txt, regex, sub=' '):\n",
    "    \n",
    "    '''This function takes in a string and a regular expression.\n",
    "    It will clean the string by removing any match from the regular expression.\n",
    "    \n",
    "    The output is the cleaned string'''\n",
    "        \n",
    "    return \" \".join(re.sub(regex, sub, txt).split()) ## Substitute the desired regex with nothing,\n",
    "                                                    ## then bring the sentence back together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af374f0-cfe3-4529-8bae-1b41c616458e",
   "metadata": {},
   "source": [
    "### Repeated instances of letters\n",
    "\n",
    "This snipet will remove letters that repeat themselves 3 times or more, and keep only a single instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c7a40b8-357e-42bc-97a2-43a4d22ef347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'yeah', 'good', 'hello', 'yas!!!']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_items = ['ooooooh', 'yeeeaaaaahhhhh', 'good', 'hello', 'yassss!!!']\n",
    "test_clean = [regex_clean(word, r'(\\w)\\1{2,}', r'\\1') for word in test_items]\n",
    "\n",
    "test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329dc040-1e6c-4a26-adac-eb9136054a64",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instances of trailing '\n",
    "\n",
    "For example: Trying -> tryin'\n",
    "This kind of spelling is quite common within song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07663eea-ac49-4303-8b32-3b840fe5dd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trying', 'handling', 'handling', \"handling'\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_items = ['tryin\\' ', 'handlin\\' ', 'handlin\\'.', 'handling\\'']\n",
    "test_clean = [regex_clean(word, r\"'\\s|'\\.\", r'g') for word in test_items]\n",
    "\n",
    "test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89cc42e-b5ab-4fcf-b095-93792a2036e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Instances of square brackets\n",
    "\n",
    "We need to remove square brackets from the lyrics, as well as what is inside the brackets.\n",
    "\n",
    "For example: \\[Chorus 1\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ad119a2-c660-4e3e-8a66-d7315f457469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I once ate an elephant', 'I will live on!', 'There will be justice.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_items = ['I once ate an elephant [It was delicious!]', '[Chorus 2] I will live on!', \n",
    "             'There [mouse] will be [rat] justice.']\n",
    "test_clean = [regex_clean(word, r'(\\[.*?\\])', r'') for word in test_items]\n",
    "\n",
    "test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b372724-38a0-43b5-bc6f-6b6755c86ea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tracking\n",
    "\n",
    "We will now keep track of how many instance of trailing ' and letter repetition there are in every song.\n",
    "We already suspect that there should be a correlation between the number of ' and the Hip Hop genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7af86cd6-eded-49ef-8732-5939c9c46b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "\n",
    "lyric_multiple_letter = [regex_clean(word, r'(\\w)\\1{2,}', r'\\1') for word in df_lyrics.Lyric] # Removing all trailing '\n",
    "lyric_clean_trail = [regex_clean(word, r\"'\\s|'\\.\", r'g') for word in df_lyrics.Lyric] # Removing triple letters or more. \n",
    "\n",
    "# Tokenising\n",
    "lyric = [nltk.wordpunct_tokenize(sentence) for sentence in df_lyrics.Lyric] # We will use this list for comparison\n",
    "\n",
    "lyric_multiple_letter = [nltk.wordpunct_tokenize(sentence) for sentence in lyric_multiple_letter]\n",
    "lyric_clean_trail = [nltk.wordpunct_tokenize(sentence) for sentence in lyric_clean_trail]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db917a3-fd3a-43ee-a9bf-a512b8c1c226",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Repeated instances of letters\n",
    "\n",
    "To count how many time letters were repeated three times or more, we use the Hamming distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0de44c36-3dae-401d-8122-cf94522577a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import hamming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e060d-4d58-40e8-b4af-b307b51e1393",
   "metadata": {},
   "source": [
    "Example of how the Hamming distance works. \n",
    "The more similar the words are, the closer to 0 the score is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42e9eb45-aadb-4d48-8fea-ddc4db5df970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming(['apple', 'apple', 'appl'], ['apple', 'apple', 'apple'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea41fcf3-147c-4020-b846-62460fc00caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming(['apple', 'apple', 'apple'], ['apple', 'apple', 'apple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d424256-85a4-4444-b8ec-d5501ce3aad6",
   "metadata": {},
   "source": [
    "We now define a function to calculate the Hamming distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba4ce597-79ca-493b-927e-7280d8161bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamham(my_lst):\n",
    "    '''This function calculates the Hamming distance between the lyrics and their tokenized version.\n",
    "    Input = list with cleaned lyrics\n",
    "    \n",
    "    Output = list containing the hamming distance between the original lyrics and the cleaned lyrics'''\n",
    "    \n",
    "    new_lst = []\n",
    "    j=0\n",
    "    for item in my_lst:\n",
    "        new_lst.append(hamming(item,lyric[j]))\n",
    "        j+=1\n",
    "    \n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e62ae6-d14e-4e99-a74b-1d45a65089c5",
   "metadata": {},
   "source": [
    "We now store the results in the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bafdef1-33a8-48d9-a0e2-173edec92317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['multiple_letter'] = hamham(lyric_multiple_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a0d67-2742-4be0-b87b-c7f86b4f63f8",
   "metadata": {},
   "source": [
    "We look at the obtained values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea38cb38-cfc5-4e75-9895-9187965dbeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    79452.000000\n",
       "mean         0.000690\n",
       "std          0.004534\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          0.276190\n",
       "Name: multiple_letter, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics['multiple_letter'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b67a1-2b27-46f4-9026-7431c053da97",
   "metadata": {},
   "source": [
    "We notice that the maximum is 0.27, which is not very high and the mean is very close to zero.\n",
    "We can assume that this feature will not have too much impact on the modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5fd764-1a73-4a4c-bd8b-f185445ba720",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Instances of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d231c53-f0cf-4ad4-a60c-021b45f46294",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trails = [len(lyric[i])-len(lyric_clean_trail[i]) for i in range(len(lyric))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf3c4923-20e2-4e1c-a7c7-6a6cafb884c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics['Trails'] = Trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdf0adf3-f541-405b-8bdb-407de0e205d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0      56526\n",
       " 2       5556\n",
       " 4       3101\n",
       " 6       1869\n",
       " 8       1425\n",
       "        ...  \n",
       " 94         1\n",
       " 167        1\n",
       " 176        1\n",
       " 100        1\n",
       "-6          1\n",
       "Name: Trails, Length: 127, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.Trails.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7459d79e-8158-4a51-946b-5b318f540378",
   "metadata": {},
   "source": [
    "There are some negative values, we set them to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ce0d975-8a1e-491e-8f6f-a69c08be623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.loc[df_lyrics['Trails'] < 0, 'Trails'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256ce3c-c739-4fd3-b762-6b16321086e6",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c14f81a-ebc4-4fd4-aca8-c9e41294bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "stpwrds = stopwords.words('english') # Import the list of stopwords.\n",
    "string.punctuation # Import the list of punctuation.\n",
    "stpwrds.extend(string.punctuation) # Merge the 2 lists together.\n",
    "\n",
    "#  Add chorus and verse to the list, as they are not part of the lyrics\n",
    "stpwrds.extend(['chorus', 'verse', 'verses', 'choruses'])\n",
    "                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e2ca7-424d-4e9e-9b12-188c1df1c29e",
   "metadata": {},
   "source": [
    "### Function Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5569c446-0b4c-4bef-b343-bc2f43705f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(song, stem='s'):\n",
    "    ''' This function takes in a string, clean it using regular expressions, tokenize it, remove\n",
    "    digits and any word shorter than 2 characters.\n",
    "    \n",
    "    It returned the clean and tokenized version of the string'''\n",
    "    assert(stem=='s' or stem=='l' or stem=='p'), '''Input a correct stemming parameter and try again.\n",
    "    The only accepted types are s for Snowball, l for Lancaster or p for Porter. Default is Snowball.'''\n",
    "    \n",
    "    song = song.lower() ## Transform the sentence into lowercase\n",
    "\n",
    "    song = regex_clean(song, r'(\\w)\\1{2,}', r'\\1') # Removing all trailing '\n",
    "    song = regex_clean(song, r\"'\\s|'\\.\", r'g') # Removing triple letters or more.\n",
    "    song = regex_clean(song, r'(\\[.*?\\])', r'') # Removing any characeters inside brackets (including brackets)\n",
    "    song = regex_clean(song, r'(\\W){2,}', r'\\1') # Removing trailing white space\n",
    "    \n",
    "    ## Tokenize \n",
    "    song = nltk.wordpunct_tokenize(song) ## tokenize the string\n",
    "\n",
    "    ## Post Token Cleaning - Stuff that applies to a list \n",
    "        \n",
    "    song = [word for word in song if word not in stpwrds] # Eliminate all extended stopwords from among our tokens\n",
    "    song = [globals()['{}_stemmer'.format(stem)].stem(word) for word in song] # Apply the chosen stemmer\n",
    "    song = [word for word in song if not word.isdigit()] # Remove all digits\n",
    "    song = [word for word in song if len(word)>2] # Remove words shorter than 2 characters, to avoid 'de, tg, ll' etc.\n",
    "\n",
    "\n",
    "    return song"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbf4c8-f8c2-42fe-b36b-b3b5ddef8050",
   "metadata": {},
   "source": [
    "Function test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a36747f-cefa-4fcf-ba31-7cb58de86981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gonna', 'hardn', 'back', 'dwag', 'word']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data(\"I am gonna go so hardn't I won't back down dwag 555!.?  ??any word\", 'p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad554222-f5a6-41c5-814d-5733b05b38b5",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e2efb-a8de-4fa9-8a3c-ff3886678a78",
   "metadata": {},
   "source": [
    "We now clean the lyrics and add them to the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32c63a9b-108f-4530-b854-c27b11646c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = [\" \".join(prep_data(x)) for x in df_lyrics['Lyric']]\n",
    "\n",
    "df_lyrics['lyrics_clean'] = lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89afdc15-bb9c-4b4d-a6b2-c059a7828f50",
   "metadata": {},
   "source": [
    "Null values verification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db78da1f-3bb5-43d2-8b00-075f7c8b6dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SName              0\n",
       "Lyric              0\n",
       "Artist             0\n",
       "Genre              0\n",
       "multiple_letter    0\n",
       "Trails             0\n",
       "lyrics_clean       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba40a18-83b4-4578-9b0a-28e959c9776f",
   "metadata": {},
   "source": [
    "### Extra features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a803a-c3c0-40f1-8859-c4f52f28af2b",
   "metadata": {},
   "source": [
    "We create a list containing the 10 most common words for each genre, after removing the 200 most popular words for the other genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f52ec684-21c2-4d8e-8d37-b402cd45b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hop = set(['nigga', 'shit', 'bitch', 'fuck', 'hit', 'gon', 'niggaz', 'with', 'bout', 'hoe', 'cuz'])\n",
    "Rock = set(['blue', 'dead', 'line', 'woman', 'child', 'cold', 'town', 'year',\n",
    "       'help', 'alive', 'behind'])\n",
    "Pop = set(['kiss', 'touch', 'christmas', 'hurt', 'beautiful', 'matter', 'somebody', 'trying', 'else', 'knew', 'forget'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f0ff0-c605-48cb-af84-81381bd0ecd6",
   "metadata": {},
   "source": [
    "We will use set manipulation to check if one of these words appear in a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0175edc-24dd-452b-943a-d200f8c52353",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lyric = [set(song) for song in lyric] # Set of the tokenized lyrics\n",
    "\n",
    "# These three lists will track if a word from the 10 most common words for each genre is present in the lyrics.\n",
    "Rock_lst = [1 if len(song&Rock)>0 else 0 for song in set_lyric]\n",
    "Pop_lst = [1 if len(song&Pop)>0 else 0 for song in set_lyric]\n",
    "Hop_lst = [1 if len(song&Hop)>0 else 0 for song in set_lyric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4910e0f-9381-451e-b420-4ae320740068",
   "metadata": {},
   "source": [
    "We now add these lists to the main dataframe, in 3 separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da0003d6-f707-4795-a4d5-f0e3e85fe9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SName</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>multiple_letter</th>\n",
       "      <th>Trails</th>\n",
       "      <th>lyrics_clean</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Hip_hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World So Cold</td>\n",
       "      <td>It starts with pain, followed by hate. Fueled ...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>start pain follow hate fuel endless question o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Broken</td>\n",
       "      <td>Freedom!. Alone again again alone. Patiently w...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>freedom alon alon patient wait phone hope call...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 Leaf Loser</td>\n",
       "      <td>Biting the hand that feeds you, lying to the v...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>bite hand feed lie voic insid reach beg someth...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anthem For The Underdog</td>\n",
       "      <td>You say you know just who I am. But you can't ...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>say know imagin wait across line thought still...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adrenaline</td>\n",
       "      <td>My heart is beating faster can't control these...</td>\n",
       "      <td>12 Stones</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0</td>\n",
       "      <td>heart beat faster control feel anymor wait lon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SName                                              Lyric  \\\n",
       "0            World So Cold  It starts with pain, followed by hate. Fueled ...   \n",
       "1                   Broken  Freedom!. Alone again again alone. Patiently w...   \n",
       "2             3 Leaf Loser  Biting the hand that feeds you, lying to the v...   \n",
       "3  Anthem For The Underdog  You say you know just who I am. But you can't ...   \n",
       "4               Adrenaline  My heart is beating faster can't control these...   \n",
       "\n",
       "      Artist  Genre  multiple_letter  Trails  \\\n",
       "0  12 Stones      0         0.000000       0   \n",
       "1  12 Stones      0         0.000000       0   \n",
       "2  12 Stones      0         0.000000       0   \n",
       "3  12 Stones      0         0.000000       2   \n",
       "4  12 Stones      0         0.007042       0   \n",
       "\n",
       "                                        lyrics_clean  Rock  Pop  Hip_hop  \n",
       "0  start pain follow hate fuel endless question o...     1    0        1  \n",
       "1  freedom alon alon patient wait phone hope call...     1    1        0  \n",
       "2  bite hand feed lie voic insid reach beg someth...     1    1        0  \n",
       "3  say know imagin wait across line thought still...     1    0        0  \n",
       "4  heart beat faster control feel anymor wait lon...     0    0        0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics = pd.concat([df_lyrics, pd.Series(Rock_lst), pd.Series(Pop_lst), pd.Series(Hop_lst)], axis=1)\n",
    "df_lyrics.rename(columns={0: 'Rock', 1:'Pop', 2:'Hip_hop'}, inplace=True)\n",
    "df_lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a254c7d-26f1-4507-b5ee-b2b9ede6072c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SName              0\n",
       "Lyric              0\n",
       "Artist             0\n",
       "Genre              0\n",
       "multiple_letter    0\n",
       "Trails             0\n",
       "lyrics_clean       0\n",
       "Rock               0\n",
       "Pop                0\n",
       "Hip_hop            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e48ac67-7cb3-4a45-a1aa-075f5cb8e923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SName                                           L'espirit D'escalier\n",
       "Lyric              All you have to do. All you have to do. Ahhhhh...\n",
       "Artist                                                           Jet\n",
       "Genre                                                              0\n",
       "multiple_letter                                             0.142857\n",
       "Trails                                                             0\n",
       "lyrics_clean                                                        \n",
       "Rock                                                               0\n",
       "Pop                                                                0\n",
       "Hip_hop                                                            0\n",
       "Name: 7509, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.iloc[7509]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba19777-403c-49fb-9176-c41fdd1d5936",
   "metadata": {},
   "source": [
    "Now that the dataframe is cleaned and ready for modelling, we export it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0217a88a-107a-493d-b45b-7351f27a6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lyrics.to_csv('./Dataset/clean_lyrics.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
